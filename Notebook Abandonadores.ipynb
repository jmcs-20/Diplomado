{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "Importaci\u00f3n de librerias"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "!pip install scikit-learn\n!pip install pixiedust", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import pixiedust", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Pixiedust database opened successfully\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "\n        <div style=\"margin:10px\">\n            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n            </a>\n            <span>Pixiedust version 1.1.19</span>\n        </div>\n        "}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#import pandas #para trabajar con bases de datos y estad\u00edsticas b\u00e1sicas en forma de matrices que acepta n\u00fameros y strings\nimport pandas as pd\n#import numpy #ayuda a operaciones con datos en forma vectorial, solo admite n\u00fameros\nimport numpy as np\n#import matplotlib #herramienta para graficar\nimport matplotlib.pyplot as plt\n#import seaborn #herramienta para graficas\nimport seaborn as sb", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Carga de archivo"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "# use pandas to import csv file\ndf = pd.read_csv('https://raw.githubusercontent.com/jmcs-20/Diplomado/main/CHURN_2.csv')\n\ndf", "execution_count": 9, "outputs": [{"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "      customerID  gender  SeniorCitizen Partner Dependents  tenure  \\\n0     5575-GNVDE    Male              0      No         No      34   \n1     7795-CFOCW    Male              0      No         No      45   \n2     9305-CDSKC  Female              0      No         No       8   \n3     6713-OKOMC  Female              0      No         No      10   \n4     6388-TABGU    Male              0      No        Yes      62   \n...          ...     ...            ...     ...        ...     ...   \n3516  9767-FFLEM    Male              0      No         No      38   \n3517  8456-QDAVC    Male              0      No         No      19   \n3518  2569-WGERO  Female              0      No         No      72   \n3519  2234-XADUH  Female              0     Yes        Yes      72   \n3520  8361-LTMKD    Male              1     Yes         No       4   \n\n     Cuenta_Corriente Multiple_CC Forma_Pago OnlineSecurity  ...  \\\n0                 Yes          No        P2C            Yes  ...   \n1                  No          No        P2C            Yes  ...   \n2                 Yes         Yes        P2P             No  ...   \n3                  No          No        P2C            Yes  ...   \n4                 Yes          No        P2C            Yes  ...   \n...               ...         ...        ...            ...  ...   \n3516              Yes          No        P2P             No  ...   \n3517              Yes          No        P2P             No  ...   \n3518              Yes          No       WIRE             No  ...   \n3519              Yes         Yes        P2P             No  ...   \n3520              Yes         Yes        P2P             No  ...   \n\n     DeviceProtection TechSupport Atencion_Telf Atencion_personal  \\\n0                 Yes          No            No                No   \n1                 Yes         Yes            No                No   \n2                 Yes          No           Yes               Yes   \n3                  No          No            No                No   \n4                  No          No            No                No   \n...               ...         ...           ...               ...   \n3516               No          No            No                No   \n3517               No          No           Yes                No   \n3518               No          No            No                No   \n3519              Yes          No           Yes               Yes   \n3520               No          No            No                No   \n\n            Contract Correspondencia MonthlyCharges  TotalCharges Churn Letra  \n0           One year              No          56.95        1889.5    No     B  \n1           One year              No          42.30       1840.75    No     D  \n2     Month-to-month             Yes          99.65         820.5   Yes     B  \n3     Month-to-month              No          29.75         301.9    No     D  \n4           One year              No          56.15       3487.95    No     B  \n...              ...             ...            ...           ...   ...   ...  \n3516  Month-to-month             Yes          69.50       2625.25    No     B  \n3517  Month-to-month             Yes          78.70        1495.1    No     D  \n3518        Two year             Yes          21.15        1419.4    No     B  \n3519        One year             Yes         103.20        7362.9    No     D  \n3520  Month-to-month             Yes          74.40         306.6   Yes     B  \n\n[3521 rows x 21 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customerID</th>\n      <th>gender</th>\n      <th>SeniorCitizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>tenure</th>\n      <th>Cuenta_Corriente</th>\n      <th>Multiple_CC</th>\n      <th>Forma_Pago</th>\n      <th>OnlineSecurity</th>\n      <th>...</th>\n      <th>DeviceProtection</th>\n      <th>TechSupport</th>\n      <th>Atencion_Telf</th>\n      <th>Atencion_personal</th>\n      <th>Contract</th>\n      <th>Correspondencia</th>\n      <th>MonthlyCharges</th>\n      <th>TotalCharges</th>\n      <th>Churn</th>\n      <th>Letra</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5575-GNVDE</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>34</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>P2C</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>56.95</td>\n      <td>1889.5</td>\n      <td>No</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7795-CFOCW</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>45</td>\n      <td>No</td>\n      <td>No</td>\n      <td>P2C</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>42.30</td>\n      <td>1840.75</td>\n      <td>No</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9305-CDSKC</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>8</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>P2P</td>\n      <td>No</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>99.65</td>\n      <td>820.5</td>\n      <td>Yes</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6713-OKOMC</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>10</td>\n      <td>No</td>\n      <td>No</td>\n      <td>P2C</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>No</td>\n      <td>29.75</td>\n      <td>301.9</td>\n      <td>No</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6388-TABGU</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>62</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>P2C</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>56.15</td>\n      <td>3487.95</td>\n      <td>No</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3516</th>\n      <td>9767-FFLEM</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>38</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>P2P</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>69.50</td>\n      <td>2625.25</td>\n      <td>No</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>3517</th>\n      <td>8456-QDAVC</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>19</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>P2P</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>78.70</td>\n      <td>1495.1</td>\n      <td>No</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>3518</th>\n      <td>2569-WGERO</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>72</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>WIRE</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Two year</td>\n      <td>Yes</td>\n      <td>21.15</td>\n      <td>1419.4</td>\n      <td>No</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>3519</th>\n      <td>2234-XADUH</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>72</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>P2P</td>\n      <td>No</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>One year</td>\n      <td>Yes</td>\n      <td>103.20</td>\n      <td>7362.9</td>\n      <td>No</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>3520</th>\n      <td>8361-LTMKD</td>\n      <td>Male</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>4</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>P2P</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>74.40</td>\n      <td>306.6</td>\n      <td>Yes</td>\n      <td>B</td>\n    </tr>\n  </tbody>\n</table>\n<p>3521 rows \u00d7 21 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Verificamos la informaci\u00f3n del conjunto de datos usando el m\u00e9todo info()"}, {"metadata": {}, "cell_type": "code", "source": "df.info()", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3521 entries, 0 to 3520\nData columns (total 21 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   customerID         3521 non-null   object \n 1   gender             3521 non-null   object \n 2   SeniorCitizen      3521 non-null   int64  \n 3   Partner            3521 non-null   object \n 4   Dependents         3521 non-null   object \n 5   tenure             3521 non-null   int64  \n 6   Cuenta_Corriente   3521 non-null   object \n 7   Multiple_CC        3521 non-null   object \n 8   Forma_Pago         3521 non-null   object \n 9   OnlineSecurity     3521 non-null   object \n 10  OnlineBackup       3521 non-null   object \n 11  DeviceProtection   3521 non-null   object \n 12  TechSupport        3521 non-null   object \n 13  Atencion_Telf      3521 non-null   object \n 14  Atencion_personal  3521 non-null   object \n 15  Contract           3521 non-null   object \n 16  Correspondencia    3521 non-null   object \n 17  MonthlyCharges     3521 non-null   float64\n 18  TotalCharges       3521 non-null   object \n 19  Churn              3521 non-null   object \n 20  Letra              3521 non-null   object \ndtypes: float64(1), int64(2), object(18)\nmemory usage: 577.8+ KB\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Revisamos la descripci\u00f3n del conjunto de datos, aqu\u00ed solo veremos las funcionalidades de num variables."}, {"metadata": {}, "cell_type": "code", "source": "df.describe()", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "       SeniorCitizen       tenure  MonthlyCharges\ncount    3521.000000  3521.000000     3521.000000\nmean        0.168134    32.638171       64.750994\nstd         0.374038    24.726521       30.135006\nmin         0.000000     0.000000       18.250000\n25%         0.000000     9.000000       35.150000\n50%         0.000000    29.000000       70.400000\n75%         0.000000    56.000000       89.950000\nmax         1.000000    72.000000      118.650000", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SeniorCitizen</th>\n      <th>tenure</th>\n      <th>MonthlyCharges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3521.000000</td>\n      <td>3521.000000</td>\n      <td>3521.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.168134</td>\n      <td>32.638171</td>\n      <td>64.750994</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.374038</td>\n      <td>24.726521</td>\n      <td>30.135006</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.250000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>35.150000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>29.000000</td>\n      <td>70.400000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>56.000000</td>\n      <td>89.950000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>72.000000</td>\n      <td>118.650000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Ahora eliminamos las caracter\u00edsticas no deseadas de nuestro conjunto de datos porque estas caracter\u00edsticas no deseadas soncomo la basura y afectar\u00e1n la precisi\u00f3n de nuestro modelo, por lo que las eliminamos."}, {"metadata": {}, "cell_type": "code", "source": "# we didn't require customerID so we drop it\ndf = df.drop('customerID',axis=1)", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ""}, {"metadata": {}, "cell_type": "code", "source": "#count of string value into the column.\ncount=0\nfor i in df.TotalCharges:\n    if i==' ':\n        count+=1\nprint('count of empty string:- ',count)\n#we will replace this empty string to nan values\ndf['TotalCharges'] = df['TotalCharges'].replace(\" \",np.nan)\n# typecasting of the TotalCharges column\ndf['TotalCharges'] = df['TotalCharges'].astype(float)", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "count of empty string:-  2\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": ""}, {"metadata": {}, "cell_type": "code", "source": "# checking null value\ndf.isnull().sum()", "execution_count": 17, "outputs": [{"output_type": "execute_result", "execution_count": 17, "data": {"text/plain": "gender               0\nSeniorCitizen        0\nPartner              0\nDependents           0\ntenure               0\nCuenta_Corriente     0\nMultiple_CC          0\nForma_Pago           0\nOnlineSecurity       0\nOnlineBackup         0\nDeviceProtection     0\nTechSupport          0\nAtencion_Telf        0\nAtencion_personal    0\nContract             0\nCorrespondencia      0\nMonthlyCharges       0\nTotalCharges         2\nChurn                0\nLetra                0\ndtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": ""}, {"metadata": {}, "cell_type": "code", "source": "# fill null values with mean\ndf['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].mean())", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#numerical variables\nnum = list(df.select_dtypes(include=['int64','float64']).keys())#categorical variables\ncat = list(df.select_dtypes(include='O').keys())\nprint(cat)\nprint(num)", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "['gender', 'Partner', 'Dependents', 'Cuenta_Corriente', 'Multiple_CC', 'Forma_Pago', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'Atencion_Telf', 'Atencion_personal', 'Contract', 'Correspondencia', 'Churn', 'Letra']\n['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# value_counts of the categorical columns\nfor i in cat:\n    print(df[i].value_counts())", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "Female    1778\nMale      1743\nName: gender, dtype: int64\nNo     1801\nYes    1720\nName: Partner, dtype: int64\nNo     2523\nYes     998\nName: Dependents, dtype: int64\nYes    3174\nNo      347\nName: Cuenta_Corriente, dtype: int64\nNo     2002\nYes    1519\nName: Multiple_CC, dtype: int64\nP2P     1552\nP2C     1201\nWIRE     768\nName: Forma_Pago, dtype: int64\nNo     2534\nYes     987\nName: OnlineSecurity, dtype: int64\nNo     2288\nYes    1233\nName: OnlineBackup, dtype: int64\nNo     2331\nYes    1190\nName: DeviceProtection, dtype: int64\nNo     2491\nYes    1030\nName: TechSupport, dtype: int64\nNo     2171\nYes    1350\nName: Atencion_Telf, dtype: int64\nNo     2148\nYes    1373\nName: Atencion_personal, dtype: int64\nMonth-to-month    1947\nTwo year           866\nOne year           708\nName: Contract, dtype: int64\nYes    2122\nNo     1399\nName: Correspondencia, dtype: int64\nNo     2606\nYes     915\nName: Churn, dtype: int64\nB    1761\nD    1760\nName: Letra, dtype: int64\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# we have to handel this all categorical variables\n# there are mainly Yes/No features in most of the columns\n# we will convert Yes = 1 and No = 0\nfor i in cat:\n    df[i] = df[i].replace('Yes',1)\n    df[i] = df[i].replace('No',0)", "execution_count": 24, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# we will convert male = 1 and female = 0\ndf.gender = df.gender.replace('Male',1)\ndf.gender = df.gender.replace('Female',0)", "execution_count": 25, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\ndf['Cuenta_Corriente'] = label.fit_transform(df['Cuenta_Corriente'])\ndf['Contract'] = label.fit_transform(df['Contract'])", "execution_count": 27, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "scale_cols = ['tenure','MonthlyCharges','TotalCharges']\n# now we scling all the data\nfrom sklearn.preprocessing import MinMaxScaler\nscale = MinMaxScaler()\ndf[scale_cols] = scale.fit_transform(df[scale_cols])", "execution_count": 28, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df = df.drop(['Forma_Pago','Letra'],axis=1)", "execution_count": 50, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# independent and dependent variables\nx = df.drop('Churn',axis=1)\ny = df['Churn']", "execution_count": 51, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2,random_state=10)\nprint(xtrain.shape)\nprint(xtest.shape)", "execution_count": 52, "outputs": [{"output_type": "stream", "text": "(2816, 17)\n(705, 17)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# import tensorflow\nimport tensorflow as tf\n#import keras\nfrom tensorflow import keras", "execution_count": 53, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# define sequential model\nmodel = keras.Sequential([\n    # input layer\n    keras.layers.Dense(17, input_shape=(17,), activation='relu'),\n    keras.layers.Dense(15, activation='relu'),\n    keras.layers.Dense(10,activation = 'relu'),\n    # we use sigmoid for binary output\n    # output layer\n    keras.layers.Dense(1, activation='sigmoid')\n]\n)", "execution_count": 57, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# time for compilation of neural net.\nmodel.compile(optimizer = 'adam',\n                loss = 'binary_crossentropy',\n                metrics = ['accuracy'])", "execution_count": 58, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# now we fit our model to training data\nmodel.fit(xtrain,ytrain,epochs=100)", "execution_count": 59, "outputs": [{"output_type": "stream", "text": "Epoch 1/100\n88/88 [==============================] - 1s 3ms/step - loss: 0.5541 - accuracy: 0.7301\nEpoch 2/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7379\nEpoch 3/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7763\nEpoch 4/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7827\nEpoch 5/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7887\nEpoch 6/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7926\nEpoch 7/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7997\nEpoch 8/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8008\nEpoch 9/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8004\nEpoch 10/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8022\nEpoch 11/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8050\nEpoch 12/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8086\nEpoch 13/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8093\nEpoch 14/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8107\nEpoch 15/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8136\nEpoch 16/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8136\nEpoch 17/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8129\nEpoch 18/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8157\nEpoch 19/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3997 - accuracy: 0.8161\nEpoch 20/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8153\nEpoch 21/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8192\nEpoch 22/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8150\nEpoch 23/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8164\nEpoch 24/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8200\nEpoch 25/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8203\nEpoch 26/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8214\nEpoch 27/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3893 - accuracy: 0.8168\nEpoch 28/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8200\nEpoch 29/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8214\nEpoch 30/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8267\nEpoch 31/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8232\nEpoch 32/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8246\nEpoch 33/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8224\nEpoch 34/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8271\nEpoch 35/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8200\nEpoch 36/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8285\nEpoch 37/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3789 - accuracy: 0.8253\nEpoch 38/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8271\nEpoch 39/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8278\nEpoch 40/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8288\nEpoch 41/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8271\nEpoch 42/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8260\nEpoch 43/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8306\nEpoch 44/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8320\nEpoch 45/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8292\nEpoch 46/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8274\nEpoch 47/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8335\nEpoch 48/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8288\nEpoch 49/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8306\nEpoch 50/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8292\nEpoch 51/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8260\nEpoch 52/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8310\nEpoch 53/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8288\nEpoch 54/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8349\nEpoch 55/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8288\nEpoch 56/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8359\nEpoch 57/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8345\nEpoch 58/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8388\nEpoch 59/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8374\nEpoch 60/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8363\nEpoch 61/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8345\nEpoch 62/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8388\nEpoch 63/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8366\nEpoch 64/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8398\nEpoch 65/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8359\nEpoch 66/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8395\nEpoch 67/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8423\nEpoch 68/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8395\nEpoch 69/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8381\nEpoch 70/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8377\nEpoch 71/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8384\nEpoch 72/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8409\nEpoch 73/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8413\nEpoch 74/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8406\nEpoch 75/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8388\nEpoch 76/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8448\nEpoch 77/100\n88/88 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8434\nEpoch 78/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8434\nEpoch 79/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8455\nEpoch 80/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8469: 0s - loss: 0.3464 - accuracy: 0.84\nEpoch 81/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8455\nEpoch 82/100\n", "name": "stdout"}, {"output_type": "stream", "text": "88/88 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8438\nEpoch 83/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3431 - accuracy: 0.8462\nEpoch 84/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8469\nEpoch 85/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8484\nEpoch 86/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8455\nEpoch 87/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8427\nEpoch 88/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8494\nEpoch 89/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8484\nEpoch 90/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8469\nEpoch 91/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8462\nEpoch 92/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8462\nEpoch 93/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8491\nEpoch 94/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8509\nEpoch 95/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8427\nEpoch 96/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8448\nEpoch 97/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8466\nEpoch 98/100\n88/88 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8509\nEpoch 99/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8462\nEpoch 100/100\n88/88 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8509\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 59, "data": {"text/plain": "<keras.callbacks.History at 0x7f735c66b310>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# evalute the model\nmodel.evaluate(xtest,ytest)", "execution_count": 60, "outputs": [{"output_type": "stream", "text": "23/23 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7901\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 60, "data": {"text/plain": "[0.4692971110343933, 0.7900709509849548]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# predict the churn values\nypred = model.predict(xtest)\nprint(ypred)\n# unscaling the ypred values\nypred_lis = []\nfor i in ypred:\n    if i>0.5:\n        ypred_lis.append(1)\n    else:\n        ypred_lis.append(0)\nprint(ypred_lis)", "execution_count": 61, "outputs": [{"output_type": "stream", "text": "[[8.57690275e-02]\n [2.04478800e-02]\n [3.06365192e-02]\n [1.70178413e-02]\n [5.23638070e-01]\n [2.25148499e-02]\n [7.72262812e-02]\n [4.12262142e-01]\n [9.48394120e-01]\n [5.29022515e-02]\n [8.31068277e-01]\n [1.22813404e-01]\n [6.09152615e-01]\n [5.72018564e-01]\n [8.18118453e-03]\n [1.35728419e-02]\n [2.41224170e-02]\n [5.98098576e-01]\n [2.33043879e-01]\n [8.32489133e-03]\n [1.03604913e-01]\n [6.70606971e-01]\n [2.41747320e-01]\n [2.45317042e-01]\n [2.18834698e-01]\n [3.33741903e-02]\n [1.95872784e-03]\n [1.50756240e-02]\n [7.19575047e-01]\n [7.15011597e-01]\n [2.31654555e-01]\n [7.84073353e-01]\n [4.34549153e-02]\n [7.72279084e-01]\n [4.10615504e-01]\n [7.90014863e-03]\n [1.09889656e-01]\n [8.37099850e-01]\n [4.71371174e-01]\n [2.56791115e-02]\n [3.02979946e-02]\n [5.80187738e-02]\n [2.50453353e-02]\n [8.18541050e-01]\n [9.79826689e-01]\n [1.65846050e-02]\n [9.80299711e-03]\n [8.12100887e-01]\n [2.72500098e-01]\n [2.10142285e-01]\n [3.62429917e-02]\n [6.86691403e-02]\n [1.75648004e-01]\n [7.28228688e-03]\n [2.20274627e-02]\n [3.75362635e-02]\n [3.34101349e-01]\n [1.44674480e-02]\n [3.12962234e-01]\n [2.37305164e-02]\n [1.91249520e-01]\n [1.23580396e-02]\n [2.76170224e-01]\n [7.35565484e-01]\n [7.38302171e-02]\n [9.11983848e-03]\n [2.09740400e-02]\n [1.72167420e-02]\n [5.19524813e-02]\n [7.74731636e-01]\n [7.46304035e-01]\n [1.53898776e-01]\n [4.62442636e-03]\n [9.85149741e-02]\n [7.97748208e-01]\n [8.66650641e-02]\n [6.74695730e-01]\n [1.36090338e-01]\n [9.27667916e-02]\n [1.11345410e-01]\n [6.11528754e-02]\n [1.87800527e-02]\n [7.14761615e-02]\n [1.08284950e-02]\n [7.22163916e-03]\n [1.96603537e-02]\n [8.61720741e-02]\n [3.73549759e-02]\n [2.48915553e-02]\n [1.62714720e-03]\n [6.53829455e-01]\n [5.71690202e-02]\n [2.35526860e-02]\n [2.29898989e-02]\n [2.02146918e-01]\n [2.01257765e-02]\n [4.55476493e-01]\n [3.05871338e-01]\n [2.92564631e-02]\n [2.79931426e-02]\n [4.69246000e-01]\n [3.47341895e-02]\n [1.88002586e-02]\n [3.11016440e-02]\n [8.43258977e-01]\n [7.71477818e-03]\n [6.29019678e-01]\n [1.12904131e-01]\n [6.70307934e-01]\n [5.04764438e-01]\n [1.91494286e-01]\n [1.00503266e-02]\n [9.84502375e-01]\n [2.40724117e-01]\n [2.79378891e-02]\n [2.40819752e-01]\n [1.06905162e-01]\n [2.72306144e-01]\n [9.28390682e-01]\n [4.04555500e-01]\n [7.99922347e-01]\n [1.31959617e-02]\n [3.01305056e-01]\n [3.16923827e-01]\n [6.94396198e-02]\n [3.35170031e-02]\n [7.16676176e-01]\n [9.32765007e-03]\n [4.74902987e-03]\n [3.95682454e-03]\n [2.03650862e-01]\n [4.21940982e-02]\n [1.46409571e-02]\n [5.30343831e-01]\n [2.21452415e-02]\n [6.92200959e-02]\n [8.63611817e-01]\n [5.82787693e-02]\n [6.26873970e-03]\n [2.35446572e-01]\n [4.12989497e-01]\n [1.03150606e-02]\n [2.08145738e-01]\n [1.44973814e-01]\n [7.10265279e-01]\n [4.06267941e-02]\n [1.21400058e-02]\n [4.14183736e-03]\n [2.22150981e-01]\n [3.68103683e-02]\n [1.58921778e-02]\n [5.37851453e-03]\n [2.31815517e-01]\n [7.94603229e-02]\n [4.32133466e-01]\n [6.94454312e-02]\n [7.67819881e-01]\n [5.63529134e-01]\n [1.92472339e-02]\n [7.05846190e-01]\n [1.14345104e-01]\n [5.03155470e-01]\n [5.17528951e-02]\n [7.66870081e-02]\n [2.25766897e-02]\n [2.22802281e-01]\n [5.46606481e-01]\n [6.63263798e-02]\n [9.46367025e-01]\n [8.34144354e-01]\n [7.73630559e-01]\n [2.43722796e-01]\n [1.79464519e-02]\n [1.10024393e-01]\n [1.32125914e-01]\n [5.01692295e-01]\n [1.26524091e-01]\n [4.43686008e-01]\n [1.48537755e-02]\n [3.44929099e-03]\n [4.85687762e-01]\n [1.68016464e-01]\n [4.90260124e-03]\n [2.12995410e-02]\n [5.54826856e-03]\n [4.57311273e-02]\n [2.10887492e-02]\n [5.10032117e-01]\n [8.91429186e-03]\n [3.40623558e-02]\n [4.63062137e-01]\n [4.88597155e-03]\n [2.88909674e-03]\n [4.11888957e-03]\n [3.44224691e-01]\n [6.56514168e-02]\n [4.26667929e-03]\n [1.53101265e-01]\n [2.19690204e-02]\n [3.53198051e-02]\n [5.24183333e-01]\n [7.84730911e-03]\n [8.83942604e-01]\n [9.48163509e-01]\n [9.22233105e-01]\n [1.98103309e-01]\n [1.96679413e-01]\n [1.38508439e-01]\n [6.34382904e-01]\n [8.59643638e-01]\n [1.97638869e-02]\n [4.60166186e-01]\n [1.37970060e-01]\n [6.41015887e-01]\n [4.13895547e-02]\n [9.31068897e-01]\n [2.12176442e-02]\n [2.75897682e-02]\n [6.78732753e-01]\n [2.86505014e-01]\n [4.50962842e-01]\n [1.05696410e-01]\n [2.39807695e-01]\n [1.17936045e-01]\n [1.98242664e-02]\n [1.17545128e-02]\n [4.33272898e-01]\n [3.03280354e-03]\n [5.17323315e-02]\n [1.37197405e-01]\n [9.16462839e-02]\n [8.59943986e-01]\n [8.94290507e-02]\n [7.18842447e-02]\n [1.12541914e-02]\n [8.39705110e-01]\n [5.19386828e-01]\n [2.12986469e-02]\n [8.54355335e-01]\n [2.18338549e-01]\n [8.81229997e-01]\n [6.91116035e-01]\n [1.17098898e-01]\n [3.40209901e-02]\n [7.58305788e-01]\n [9.95934010e-03]\n [5.94901741e-01]\n [5.50986528e-01]\n [4.48955297e-01]\n [4.55006182e-01]\n [1.71235412e-01]\n [9.58114862e-02]\n [6.41964734e-01]\n [1.95451081e-01]\n [4.51995134e-02]\n [7.82224536e-03]\n [3.65626812e-03]\n [6.07893050e-01]\n [2.86706686e-02]\n [4.68321532e-01]\n [8.93121839e-01]\n [6.93042159e-01]\n [1.67867750e-01]\n [1.21980578e-01]\n [1.19182497e-01]\n [2.03912258e-02]\n [6.75071597e-01]\n [3.47010493e-02]\n [5.65269589e-02]\n [8.87864888e-01]\n [5.64269185e-01]\n [2.95277059e-01]\n [9.52716768e-02]\n [1.60108298e-01]\n [7.85544813e-02]\n [5.53747058e-01]\n [1.68844759e-02]\n [3.41100395e-02]\n [4.15343046e-03]\n [2.72489309e-01]\n [4.54805225e-01]\n [5.68136573e-03]\n [5.73931813e-01]\n [5.65849841e-02]\n [6.93759322e-01]\n [2.02469021e-01]\n [1.66415423e-01]\n [1.97203100e-01]\n [8.17589223e-01]\n [7.28555918e-02]\n [4.08620358e-01]\n [4.19941545e-03]\n [1.12255305e-01]\n [7.56011844e-01]\n [7.22500980e-02]\n [4.91783321e-01]\n [2.20052481e-01]\n [1.57336056e-01]\n [1.63295865e-03]\n [4.15295362e-03]\n [1.07755870e-01]\n [1.76249444e-02]\n [5.07348776e-03]\n [5.16202748e-02]\n [3.92353237e-02]\n [9.01493907e-01]\n [5.30172408e-01]\n [1.67103112e-02]\n [9.56066251e-02]\n [3.88341844e-02]\n [3.07107866e-01]\n [1.00867301e-01]\n [5.96836925e-01]\n [7.31828809e-03]\n [9.92062092e-02]\n [8.40945244e-01]\n [7.08216906e-01]\n [6.74574971e-01]\n [2.28878558e-02]\n [6.98640823e-01]\n [6.95116818e-02]\n [3.32530439e-02]\n [1.03922367e-01]\n [3.16431522e-02]\n [3.29055786e-02]\n [5.01646936e-01]\n [4.37900424e-03]\n [7.86079049e-01]\n [3.09675932e-04]\n [7.36354291e-02]\n [3.00204754e-03]\n [9.58788335e-01]\n [1.56511873e-01]\n [8.09316039e-02]\n [7.27108419e-02]\n [3.90879750e-01]\n [2.11219788e-02]\n [4.02316451e-02]\n [1.49950147e-01]\n [1.21610552e-01]\n [5.04663765e-01]\n [3.15467238e-01]\n [6.84371591e-03]\n [7.44234920e-02]\n [5.00709713e-02]\n [3.52213949e-01]\n [8.69998336e-01]\n [5.15916944e-03]\n [3.29234749e-01]\n [1.89355016e-02]\n [8.03491473e-03]\n [7.31709838e-01]\n [6.77887619e-01]\n [9.90096033e-02]\n [2.85554349e-01]\n [7.12929845e-01]\n [1.69116586e-01]\n [5.38324714e-01]\n [2.23901749e-01]\n [2.19926357e-01]\n [5.91951013e-01]\n [1.34622157e-02]\n [5.76279581e-01]\n [1.65440530e-01]\n [1.35094523e-02]\n [8.30402970e-03]\n [8.00162673e-01]\n [1.09672487e-01]\n [1.19266808e-02]\n [4.49377298e-03]\n [4.70701158e-02]\n [1.58377796e-01]\n [9.11324918e-01]\n [2.86430120e-03]\n [1.56859547e-01]\n [9.97239351e-03]\n [6.97872400e-01]\n [3.05827856e-01]\n [2.38708258e-02]\n [9.92944837e-03]\n [1.30302966e-01]\n [3.15758467e-01]\n [4.08541948e-01]\n [2.04932451e-01]\n [6.88233972e-03]\n [1.81985140e-01]\n [9.42860246e-02]\n [7.46400297e-01]\n [7.30508566e-03]\n [6.85564280e-02]\n [1.86067820e-03]\n [4.26065922e-03]\n [4.61321771e-02]\n [4.20644879e-01]\n [5.08218706e-02]\n [4.30082381e-02]\n [5.30017018e-01]\n [1.66237950e-02]\n [2.10884213e-03]\n [6.86626911e-01]\n [4.58582759e-01]\n [8.28989863e-01]\n [7.90841579e-02]\n [6.29635334e-01]\n [3.92920882e-01]\n [9.27336812e-01]\n [1.22572780e-01]\n [6.08332455e-01]\n [2.00037956e-02]\n [7.98277855e-02]\n [6.85158372e-03]\n [1.75086766e-01]\n [5.42932749e-03]\n [4.10718113e-01]\n [8.12077641e-01]\n [7.78369784e-01]\n [7.01908708e-01]\n [3.44710469e-01]\n [2.29756832e-02]\n [1.67126924e-01]\n [5.56185305e-01]\n [1.12884164e-01]\n [6.51396990e-01]\n [6.90387130e-01]\n [7.68767297e-02]\n [8.34151328e-01]\n [5.09982109e-02]\n [9.96477008e-02]\n [5.45127153e-01]\n [1.90967590e-01]\n [4.69164252e-01]\n [2.88580656e-01]\n [6.48792803e-01]\n [1.82824135e-02]\n [7.85200357e-01]\n [6.29256546e-01]\n [1.16956472e-01]\n [5.00213087e-01]\n [5.87276638e-01]\n [1.18191659e-01]\n [1.28281146e-01]\n [4.04377878e-02]\n [5.67293167e-03]\n [3.48115563e-02]\n [4.10599709e-02]\n [2.31752187e-01]\n [1.14414722e-01]\n [2.67623663e-02]\n [9.20312881e-01]\n [1.69268310e-01]\n [3.58974636e-02]\n [3.61574590e-02]\n [8.25117052e-01]\n [6.84056342e-01]\n [5.50583005e-02]\n [1.84470415e-02]\n [2.08806694e-02]\n [3.25697899e-01]\n [5.04261494e-01]\n [4.70569283e-01]\n [4.84630466e-03]\n [2.93539762e-02]\n [7.39529729e-03]\n [3.36582363e-02]\n [1.42889619e-02]\n [3.94019186e-02]\n [8.69859457e-01]\n [1.12417907e-01]\n [8.85963976e-01]\n [2.26773322e-02]\n [9.48319316e-01]\n [5.52097321e-01]\n [2.79225111e-02]\n [7.84389794e-01]\n [5.73504627e-01]\n [3.50536078e-01]\n [1.04534626e-03]\n [1.23042643e-01]\n [8.87796640e-01]\n [7.89985299e-01]\n [7.46779203e-01]\n [2.46344537e-01]\n [6.02397621e-02]\n [7.15355515e-01]\n [5.44924438e-02]\n [2.25739956e-01]\n [2.55493820e-02]\n [4.84782457e-03]\n [1.97103560e-01]\n [5.84088564e-01]\n [2.44177073e-01]\n [1.92443728e-02]\n [6.32965565e-03]\n [3.78916860e-02]\n [4.09806788e-01]\n [2.54016578e-01]\n [4.54521179e-03]\n [4.15313780e-01]\n [7.25266755e-01]\n [4.49349254e-01]\n [6.29058480e-03]\n [2.00019360e-01]\n [5.66538095e-01]\n [5.44500351e-03]\n [6.75472617e-03]\n [2.08890080e-01]\n [1.09636605e-01]\n [1.10134751e-01]\n [3.24159861e-04]\n [1.28952026e-01]\n [4.81829047e-03]\n [1.09958351e-02]\n [2.98385918e-01]\n [1.66698933e-01]\n [6.85438514e-03]\n [1.53889656e-02]\n [9.48367894e-01]\n [2.53066123e-01]\n [9.01305556e-01]\n [8.00589919e-01]\n [6.34963870e-01]\n [6.87552333e-01]\n [2.93715298e-02]\n [8.36413443e-01]\n [2.04818845e-02]\n [1.16952419e-01]\n [8.37549329e-01]\n [9.56583023e-02]\n [7.43258357e-01]\n [3.35870087e-02]\n [8.74516368e-03]\n [7.90292025e-02]\n [2.53095627e-02]\n [1.55424446e-01]\n [8.81337047e-01]\n [4.57908213e-02]\n [7.78856874e-03]\n [1.73846483e-02]\n [3.20929885e-02]\n [1.83047324e-01]\n [3.10022235e-02]\n [9.88337696e-02]\n [1.13524348e-01]\n [9.50392783e-02]\n [9.51864004e-01]\n [1.81573093e-01]\n [1.82538927e-02]\n [5.57773709e-02]\n [2.79432237e-01]\n [5.33139706e-03]\n [7.69705951e-01]\n [7.68071055e-01]\n [6.24811649e-03]\n [7.92887330e-01]\n [1.31935537e-01]\n [1.52802438e-01]\n [6.04078650e-01]\n [1.77549154e-01]\n [1.23722851e-02]\n [1.23001456e-01]\n [8.03511202e-01]\n [1.50895119e-02]\n [4.46664155e-01]\n [6.76746428e-01]\n [4.04071510e-02]\n [1.99812025e-01]\n [4.56146002e-02]\n [1.69777721e-01]\n [1.00968540e-01]\n [6.30034924e-01]\n [2.35158950e-01]\n [3.71624827e-02]\n [2.96107233e-02]\n [2.17467546e-02]\n [4.02050614e-02]\n [7.29733050e-01]\n [1.27479434e-02]\n [1.00142568e-01]\n [7.90427327e-01]\n [7.78630376e-03]\n [1.45330131e-02]\n [9.45456624e-01]\n [3.15666497e-02]\n [1.64507210e-01]\n [7.34757185e-02]\n [4.57564473e-01]\n [8.36060345e-02]\n [1.13324881e-01]\n [2.47510970e-02]\n [6.94546819e-01]\n [2.36330628e-02]\n [9.70511198e-01]\n [8.44061553e-01]\n [2.02839017e-01]\n [8.33702087e-03]\n [7.46039271e-01]\n [9.51963663e-03]\n [8.63851011e-02]\n [1.47253275e-02]\n [4.00735706e-01]\n [5.08981943e-03]\n [8.41089487e-01]\n [1.07868314e-02]\n [8.95882845e-02]\n [9.52785015e-02]\n [2.23740637e-02]\n [8.56744766e-01]\n [5.88932037e-01]\n [1.70016289e-02]\n [2.30231375e-01]\n [7.76684284e-03]\n [4.60655391e-01]\n [2.38878638e-01]\n [1.49783134e-01]\n [8.32115054e-01]\n [1.08097851e-01]\n [4.58090305e-02]\n [4.71260548e-02]\n [1.51128024e-01]\n [2.11329341e-01]\n [8.22594762e-03]\n [7.57738650e-02]\n [6.87571466e-01]\n [2.30678886e-01]\n [3.11586261e-03]\n [2.75158823e-01]\n [8.30221176e-02]\n [1.12493038e-02]\n [5.14350176e-01]\n [7.77342916e-03]\n [6.81570530e-01]\n [6.77742660e-02]\n [7.71356583e-01]\n [1.23442829e-01]\n [1.14983022e-02]\n [2.94739902e-02]\n [5.73030114e-03]\n [4.16515112e-01]\n [7.46579528e-01]\n [3.16388011e-01]\n [1.00694984e-01]\n [4.23628092e-03]\n [2.08827853e-02]\n [3.49370986e-01]\n [4.32305932e-02]\n [3.66809726e-01]\n [1.25400722e-02]\n [2.25833952e-01]\n [8.72941017e-02]\n [6.93430543e-01]\n [8.14993203e-01]\n [2.99352884e-01]\n [2.16538608e-02]\n [1.73943460e-01]\n [1.81042850e-02]\n [4.14791822e-01]\n [9.22279358e-02]\n [7.49014735e-01]\n [8.60040903e-01]\n [4.52918798e-01]\n [1.40290558e-02]\n [9.83621776e-02]\n [7.76096284e-02]\n [4.73026603e-01]\n [6.64770603e-04]\n [2.60614872e-01]\n [4.15302604e-01]\n [7.32501507e-01]\n [2.21266836e-01]\n [3.08610529e-01]\n [1.32335424e-02]\n [4.02128696e-03]\n [3.96692753e-03]\n [2.44561464e-01]\n [5.11450648e-01]\n [4.08934355e-02]\n [8.19593906e-01]\n [8.84032249e-01]\n [3.62661034e-01]\n [1.24807656e-02]\n [2.16019213e-01]\n [1.12797141e-01]\n [8.31077337e-01]\n [3.19480002e-02]\n [3.03233624e-01]\n [7.28817999e-01]\n [4.22453880e-03]\n [7.17794478e-01]\n [2.28346586e-02]\n [1.09024853e-01]\n [5.91206849e-02]\n [3.97859126e-01]\n [7.33398438e-01]\n [2.21729279e-03]\n [8.14577639e-02]\n [9.60284472e-03]\n [8.95518899e-01]\n [1.00187957e-01]\n [5.02480805e-01]\n [2.04941511e-01]\n [1.78621858e-01]\n [2.60086954e-02]\n [2.26556957e-02]\n [3.83545578e-01]\n [3.90869379e-02]]\n[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#make dataframe for comparing the orignal and predict values\ndata = {'orignal_churn':ytest, 'predicted_churn':ypred_lis}\ndf_check = pd.DataFrame(data)\ndf_check.head(10)", "execution_count": 62, "outputs": [{"output_type": "execute_result", "execution_count": 62, "data": {"text/plain": "      orignal_churn  predicted_churn\n2920              1                0\n2355              0                0\n1825              0                0\n3376              0                0\n176               1                1\n2371              0                0\n3342              0                0\n2046              0                0\n865               1                1\n1112              0                0", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>orignal_churn</th>\n      <th>predicted_churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2920</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2355</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1825</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3376</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2371</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3342</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2046</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>865</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1112</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# checking for performance metrices\n#importing classification_report and confusion metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\n#print classification_report\nprint(classification_report(ytest,ypred_lis))\n# ploting the confusion metrix plot\nconf_mat = tf.math.confusion_matrix(labels=ytest,predictions=ypred_lis)\nplt.figure(figsize = (17,7))\nsb.heatmap(conf_mat, annot=True,fmt='d')\nplt.xlabel('Predicted_number')\nplt.ylabel('True_number')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}